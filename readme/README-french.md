# Laboratoire d'Agent : Utilisation des agents LLM comme assistants de recherche

<p align="center">
  <img src="../media/AgentLabLogo.png" alt="DÃ©monstration du flux de AgentClinic" style="width: 99%;">
</p>


<p align="center">
    ã€<a href="../README.md">English</a> | <a href="../readme/README-chinese.md">ä¸­æ–‡</a> | <a href="../readme/README-japanese.md">æ—¥æœ¬èª</a> | <a href="../readme/README-korean.md">í•œêµ­ì–´</a> | <a href="../readme/README-filipino.md">Filipino</a> | FranÃ§ais | <a href="../readme/README-slovak.md">SlovenÄina</a> | <a href="../readme/README-portugese.md">PortuguÃªs</a> | <a href="../readme/README-spanish.md">EspaÃ±ol</a> | <a href="../readme/README-turkish.md">TÃ¼rkÃ§e</a> | <a href="../readme/README-hindi.md">à¤¹à¤¿à¤‚à¤¦à¥€</a> | <a href="../readme/README-bengali.md">à¦¬à¦¾à¦‚à¦²à¦¾</a> | <a href="../readme/README-vietnamese.md">Tiáº¿ng Viá»‡t</a> | <a href="../readme/README-russian.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> | <a href="../readme/README-arabic.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> | <a href="../readme/README-farsi.md">ÙØ§Ø±Ø³ÛŒ</a> | <a href="../readme/README-italian.md">Italiano</a>ã€‘
</p>

<p align="center">
    ã€ğŸŒ <a href="https://agentlaboratory.github.io/">Site Web</a> | ğŸ’» <a href="https://github.com/SamuelSchmidgall/AgentLaboratory">Logiciel</a> | ğŸ¥ <a href="https://agentlaboratory.github.io/#youtube-video">VidÃ©o</a> |  ğŸ“š <a href="https://agentlaboratory.github.io/#examples-goto">Article Exemple</a> | ğŸ“° <a href="https://agentlaboratory.github.io/#citation-ref">Citation</a>ã€‘
</p>

## ğŸ“– AperÃ§u

- **Laboratoire d'Agent** est un flux de travail de recherche autonome de bout en bout destinÃ© Ã  vous assister en tant que chercheur humain dans **la mise en Å“uvre de vos idÃ©es de recherche**. Le Laboratoire d'Agent est composÃ© d'agents spÃ©cialisÃ©s alimentÃ©s par de grands modÃ¨les de langage pour vous soutenir tout au long du processus de rechercheâ€”de la rÃ©alisation des revues de littÃ©rature et de la formulation de plans Ã  l'exÃ©cution des expÃ©riences et Ã  la rÃ©daction de rapports complets.
- Ce systÃ¨me n'est pas conÃ§u pour remplacer votre crÃ©ativitÃ©, mais pour la complÃ©ter, vous permettant de vous concentrer sur lâ€™idÃ©ation et la pensÃ©e critique tout en automatisant les tÃ¢ches rÃ©pÃ©titives et chronophages telles que la programmation et la documentation. En s'adaptant Ã  diffÃ©rents niveaux de ressources informatiques et d'implication humaine, le Laboratoire d'Agent vise Ã  accÃ©lÃ©rer la dÃ©couverte scientifique et Ã  optimiser votre productivitÃ© en recherche.

<p align="center">
  <img src="../media/AgentLab.png" alt="DÃ©monstration du flux de AgentClinic" style="width: 99%;">
</p>

### ğŸ”¬ Comment fonctionne le Laboratoire d'Agent ?

- Le Laboratoire d'Agent se compose de trois phases principales qui guident systÃ©matiquement le processus de recherche : (1) Revue de littÃ©rature, (2) ExpÃ©rimentation et (3) RÃ©daction de rapports. Pendant chaque phase, des agents spÃ©cialisÃ©s alimentÃ©s par des LLM collaborent pour atteindre des objectifs distincts, en intÃ©grant des outils externes tels qu'arXiv, Hugging Face, Python et LaTeX afin d'optimiser les rÃ©sultats. Ce flux de travail structurÃ© commence par la collecte et l'analyse indÃ©pendantes des articles de recherche pertinents, progresse par la planification collaborative et la prÃ©paration des donnÃ©es, et aboutit Ã  l'expÃ©rimentation automatisÃ©e et Ã  la gÃ©nÃ©ration de rapports complets. Les dÃ©tails sur les rÃ´les spÃ©cifiques des agents et leurs contributions au cours de ces phases sont abordÃ©s dans l'article.

<p align="center">
  <img src="../media/AgentLabWF.png" alt="DÃ©monstration du flux de AgentClinic" style="width: 99%;">
</p>

## ğŸ–¥ï¸ Installation

### Option d'environnement virtuel Python

1. **Cloner le dÃ©pÃ´t GitHub** : Commencez par cloner le dÃ©pÃ´t en utilisant la commande :
    ```bash
    git clone git@github.com:SamuelSchmidgall/AgentLaboratory.git
    ```

2. **Configurer et activer l'environnement Python**
    ```bash
    python -m venv venv_agent_lab
    ```

    - Activez maintenant cet environnement :
    ```bash
    source venv_agent_lab/bin/activate
    ```

3. **Installer les bibliothÃ¨ques requises**
    ```bash
    pip install -r requirements.txt
    ```

4. **Installer pdflatex [OPTIONNEL]**
    ```bash
    sudo apt install pdflatex
    ```

    - Cela permet aux agents de compiler le code source LaTeX.
    - **[IMPORTANT]** Si cette Ã©tape ne peut pas Ãªtre exÃ©cutÃ©e en raison de l'absence d'accÃ¨s sudo, la compilation PDF peut Ãªtre dÃ©sactivÃ©e en exÃ©cutant le Laboratoire d'Agent avec le drapeau `--compile_latex` dÃ©fini sur `false` : `--compile_latex=False`

5. **Lancez maintenant le Laboratoire d'Agent !**
    ```bash
    python ai_lab_repo.py --api-key "API_KEY_HERE" --llm-backend "o1-mini" --research-topic "VOTRE IDÃ‰E DE RECHERCHE"
    ```

    ou, si vous n'avez pas installÃ© pdflatex

    ```bash
    python ai_lab_repo.py --api-key "API_KEY_HERE" --llm-backend "o1-mini" --research-topic "VOTRE IDÃ‰E DE RECHERCHE" --compile_latex=False
    ```

-----
## Conseils pour de meilleurs rÃ©sultats de recherche

#### [Conseil nÂ°1] ğŸ“ Assurez-vous de prendre des notes dÃ©taillÃ©es ! ğŸ“

**Prendre des notes dÃ©taillÃ©es est important** pour aider votre agent Ã  comprendre ce que vous cherchez Ã  accomplir dans votre projet, ainsi que toute prÃ©fÃ©rence de style. Les notes peuvent inclure les expÃ©riences que vous souhaitez que les agents rÃ©alisent, la fourniture de clÃ©s API, certains graphiques ou figures que vous souhaitez inclure, ou tout ce que vous souhaitez que l'agent sache lors de la rÃ©alisation de recherches.

C'est Ã©galement votre opportunitÃ© d'informer l'agent **quelles ressources informatiques il peut utiliser**, par exemple les GPU (combien, quel type de GPU, combien de Go), les CPU (combien de cÅ“urs, quel type de CPU), les limitations de stockage et les spÃ©cifications matÃ©rielles.

Pour ajouter des notes, vous devez modifier la structure `task_notes_LLM` Ã  l'intÃ©rieur de `ai_lab_repo.py`. Ci-dessous, un exemple de jeu de notes utilisÃ© pour certaines de nos expÃ©riences.

```python
task_notes_LLM = [
    {"phases": ["plan formulation"],
     "note": f"You should come up with a plan for TWO experiments."},

    {"phases": ["plan formulation", "data preparation",  "running experiments"],
     "note": "Please use gpt-4o-mini for your experiments."},

    {"phases": ["running experiments"],
     "note": f"Use the following code to inference gpt-4o-mini: \nfrom openai import OpenAI\nos.environ["OPENAI_API_KEY"] = "{api_key}"\nclient = OpenAI()\ncompletion = client.chat.completions.create(\nmodel="gpt-4o-mini-2024-07-18", messages=messages)\nanswer = completion.choices[0].message.content\n"},

    {"phases": ["running experiments"],
     "note": f"You have access to only gpt-4o-mini using the OpenAI API, please use the following key {api_key} but do not use too many inferences. Do not use openai.ChatCompletion.create or any openai==0.28 commands. Instead use the provided inference code."},

    {"phases": ["running experiments"],
     "note": "I would recommend using a small dataset (approximately only 100 data points) to run experiments in order to save time. Do not use much more than this unless you have to or are running the final tests."},

    {"phases": ["data preparation", "running experiments"],
     "note": "You are running on a MacBook laptop. You can use 'mps' with PyTorch"},

    {"phases": ["data preparation", "running experiments"],
     "note": "Generate figures with very colorful and artistic design."},
    ]
```

--------
    
#### [Conseil nÂ°2] ğŸš€ Utiliser des modÃ¨les plus puissants conduit gÃ©nÃ©ralement Ã  une meilleure recherche ğŸš€

Lors de la conduite de recherches, **le choix du modÃ¨le peut avoir un impact significatif sur la qualitÃ© des rÃ©sultats**. Les modÃ¨les plus puissants ont tendance Ã  avoir une prÃ©cision plus Ã©levÃ©e, de meilleures capacitÃ©s de raisonnement et une meilleure gÃ©nÃ©ration de rapports. Si les ressources informatiques le permettent, privilÃ©giez l'utilisation de modÃ¨les avancÃ©s tels que o1-(mini/preview) ou d'autres grands modÃ¨les de langage Ã  la pointe de la technologie.

Cependant, **il est important de trouver un Ã©quilibre entre performance et rentabilitÃ©**. Bien que les modÃ¨les puissants puissent donner de meilleurs rÃ©sultats, ils sont souvent plus coÃ»teux et plus longs Ã  exÃ©cuter. Envisagez de les utiliser de maniÃ¨re sÃ©lectiveâ€”par exemple, pour des expÃ©riences clÃ©s ou des analyses finalesâ€”tout en comptant sur des modÃ¨les plus petits et plus efficaces pour des tÃ¢ches itÃ©ratives ou du prototypage initial.

Lorsque les ressources sont limitÃ©es, **optimisez en affinant des modÃ¨les plus petits** sur votre jeu de donnÃ©es spÃ©cifique ou en combinant des modÃ¨les prÃ©-entraÃ®nÃ©s avec des invites spÃ©cifiques Ã  la tÃ¢che afin d'atteindre l'Ã©quilibre souhaitÃ© entre performance et efficacitÃ© computationnelle.

-----

#### [Conseil nÂ°3] âœ… Vous pouvez charger des sauvegardes prÃ©cÃ©dentes depuis des points de contrÃ´le âœ…

**Si vous perdez des progrÃ¨s, la connexion Internet ou si une sous-tÃ¢che Ã©choue, vous pouvez toujours charger Ã  partir d'un Ã©tat prÃ©cÃ©dent.** Tous vos progrÃ¨s sont enregistrÃ©s par dÃ©faut dans la variable `state_saves`, qui stocke chaque point de contrÃ´le individuel. Il vous suffit de passer les arguments suivants lors de l'exÃ©cution de `ai_lab_repo.py`

```bash
python ai_lab_repo.py --api-key "API_KEY_HERE" --research-topic "YOUR RESEARCH IDEA" --llm-backend "o1-mini" --load-existing True --load-existing-path "save_states/LOAD_PATH"
```

-----

#### [Conseil nÂ°4] ğŸˆ¯ Si vous utilisez une langue autre que l'anglais ğŸˆ²

Si vous exÃ©cutez le Laboratoire d'Agent dans une langue autre que l'anglais, pas de problÃ¨me, assurez-vous simplement de fournir un drapeau de langue aux agents pour effectuer des recherches dans votre langue prÃ©fÃ©rÃ©e. Notez que nous n'avons pas Ã©tudiÃ© de maniÃ¨re approfondie l'exÃ©cution du Laboratoire d'Agent dans d'autres langues, alors assurez-vous de signaler tout problÃ¨me que vous rencontrez.

Par exemple, si vous utilisez le chinois :

```bash
python ai_lab_repo.py --api-key "API_KEY_HERE" --research-topic "YOUR RESEARCH IDEA (in your language)" --llm-backend "o1-mini" --language "ä¸­æ–‡"
```

----

#### [Conseil nÂ°5] ğŸŒŸ Il y a beaucoup de place pour l'amÃ©lioration ğŸŒŸ

Il y a beaucoup de possibilitÃ©s d'amÃ©liorer cette base de code, donc si vous finissez par apporter des modifications et souhaitez aider la communautÃ©, n'hÃ©sitez pas Ã  partager les changements que vous avez effectuÃ©s ! Nous espÃ©rons que cet outil vous sera utile !

## RÃ©fÃ©rence / Bibtex

```bibtex
@preprint{schmidgall2025AgentLaboratory,
  title={Agent Laboratory: Using LLM Agents as Research Assistants},
  author={Schmidgall, Samuel and Su, Yusheng and Wang, Ze and Sun, Ximeng and Wu, Jialian and Yu, Xiadong and Liu, Jiang, Liu, Zicheng and Barsoum, Emad},
  year={2025}
}
```