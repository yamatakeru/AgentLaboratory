# Agent Laboratory: Usando Agentes LLM como Assistentes de Pesquisa

<p align="center">
  <img src="../media/AgentLabLogo.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>


<p align="center">
    ã€<a href="../README.md">English</a> | <a href="../readme/README-chinese.md">ä¸­æ–‡</a> | <a href="../readme/README-japanese.md">æ—¥æœ¬èª</a> | <a href="../readme/README-korean.md">í•œêµ­ì–´</a> | <a href="../readme/README-filipino.md">Filipino</a> | <a href="../readme/README-french.md">FranÃ§ais</a> | <a href="../readme/README-slovak.md">SlovenÄina</a> | PortuguÃªs | <a href="../readme/README-spanish.md">EspaÃ±ol</a> | <a href="../readme/README-turkish.md">TÃ¼rkÃ§e</a> | <a href="../readme/README-hindi.md">à¤¹à¤¿à¤‚à¤¦à¥€</a> | <a href="../readme/README-bengali.md">à¦¬à¦¾à¦‚à¦²à¦¾</a> | <a href="../readme/README-vietnamese.md">Tiáº¿ng Viá»‡t</a> | <a href="../readme/README-russian.md">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> | <a href="../readme/README-arabic.md">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> | <a href="../readme/README-farsi.md">ÙØ§Ø±Ø³ÛŒ</a> | <a href="../readme/README-italian.md">Italiano</a>ã€‘
</p>

<p align="center">
    ã€ğŸŒ <a href="https://agentlaboratory.github.io/">Website</a> | ğŸ’» <a href="https://github.com/SamuelSchmidgall/AgentLaboratory">Software</a> | ğŸ¥ <a href="https://agentlaboratory.github.io/#youtube-video">Video</a> |  ğŸ“š <a href="https://agentlaboratory.github.io/#examples-goto">Example Paper</a> | ğŸ“° <a href="https://agentlaboratory.github.io/#citation-ref">Citation</a>ã€‘
</p>

## ğŸ“– VisÃ£o Geral

- **Agent Laboratory** Ã© um fluxo de trabalho de pesquisa autÃ´nomo de ponta a ponta, destinado a auxiliar **vocÃª** como pesquisador humano na **implementaÃ§Ã£o das suas ideias de pesquisa**. O Agent Laboratory consiste em agentes especializados movidos por grandes modelos de linguagem para apoiÃ¡-lo durante todo o fluxo de trabalho de pesquisa â€” desde a conduÃ§Ã£o de revisÃµes de literatura e formulaÃ§Ã£o de planos atÃ© a execuÃ§Ã£o de experimentos e a redaÃ§Ã£o de relatÃ³rios abrangentes.
- Este sistema nÃ£o foi projetado para substituir a sua criatividade, mas para complementÃ¡-la, permitindo que vocÃª se concentre na ideaÃ§Ã£o e no pensamento crÃ­tico enquanto automatiza tarefas repetitivas e que consomem muito tempo, como codificaÃ§Ã£o e documentaÃ§Ã£o. Ao acomodar diferentes nÃ­veis de recursos computacionais e envolvimento humano, o Agent Laboratory visa acelerar a descoberta cientÃ­fica e otimizar a sua produtividade em pesquisa.

<p align="center">
  <img src="../media/AgentLab.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>

### ğŸ”¬ Como funciona o Agent Laboratory?

- O Agent Laboratory consiste em trÃªs fases principais que orientam sistematicamente o processo de pesquisa: (1) RevisÃ£o de Literatura, (2) ExperimentaÃ§Ã£o e (3) RedaÃ§Ã£o de RelatÃ³rios. Durante cada fase, agentes especializados movidos por LLMs colaboram para alcanÃ§ar objetivos distintos, integrando ferramentas externas como arXiv, Hugging Face, Python e LaTeX para otimizar os resultados. Este fluxo de trabalho estruturado comeÃ§a com a coleta e anÃ¡lise independentes de artigos de pesquisa relevantes, avanÃ§a atravÃ©s do planejamento colaborativo e preparaÃ§Ã£o de dados, e resulta em experimentaÃ§Ã£o automatizada e geraÃ§Ã£o de relatÃ³rios abrangentes. Detalhes sobre os papÃ©is especÃ­ficos dos agentes e suas contribuiÃ§Ãµes ao longo dessas fases sÃ£o discutidos no artigo.

<p align="center">
  <img src="../media/AgentLabWF.png" alt="Demonstration of the flow of AgentClinic" style="width: 99%;">
</p>

## ğŸ–¥ï¸ InstalaÃ§Ã£o

### OpÃ§Ã£o de ambiente virtual Python (venv)

1. **Clone o RepositÃ³rio do GitHub**: Comece clonando o repositÃ³rio usando o comando:
    ```bash
    git clone git@github.com:SamuelSchmidgall/AgentLaboratory.git
    ```

2. **Configure e Ative o Ambiente Python**
    ```bash
    python -m venv venv_agent_lab
    ```

    - Agora, ative este ambiente:
    ```bash
    source venv_agent_lab/bin/activate
    ```

3. **Instale as bibliotecas necessÃ¡rias**
    ```bash
    pip install -r requirements.txt
    ```

4. **Instale o pdflatex [OPCIONAL]**
    ```bash
    sudo apt install pdflatex
    ```

    - Isso permite que o cÃ³digo LaTeX seja compilado pelos agentes.
    - **[IMPORTANTE]** Se esta etapa nÃ£o puder ser executada devido Ã  falta de acesso sudo, a compilaÃ§Ã£o de PDF pode ser desativada executando o Agent Laboratory com a flag --compile_latex definida como false: --compile_latex=False

5. **Agora execute o Agent Laboratory!**

    ```bash
    python ai_lab_repo.py --api-key "API_KEY_AQUI" --llm-backend "o1-mini" --research-topic "SUA IDEIA DE PESQUISA"
    ```

    ou, se vocÃª nÃ£o tiver o pdflatex instalado

    ```bash
    python ai_lab_repo.py --api-key "API_KEY_AQUI" --llm-backend "o1-mini" --research-topic "SUA IDEIA DE PESQUISA" --compile_latex=False
    ```

-----
## Dicas para melhores resultados de pesquisa

#### [Dica #1] ğŸ“ Certifique-se de escrever notas extensas! ğŸ“

**Escrever notas extensas Ã© importante** para ajudar seu agente a entender o que vocÃª estÃ¡ tentando realizar em seu projeto, bem como quaisquer preferÃªncias de estilo. As notas podem incluir quaisquer experimentos que vocÃª deseja que os agentes realizem, fornecendo chaves de API, certos grÃ¡ficos ou figuras que vocÃª deseja incluir, ou qualquer coisa que vocÃª queira que o agente saiba ao realizar a pesquisa.

Esta tambÃ©m Ã© sua oportunidade de informar ao agente **a quais recursos de computaÃ§Ã£o ele tem acesso**, por exemplo, GPUs (quantas, que tipo de GPU, quantos GBs), CPUs (quantos nÃºcleos, que tipo de CPUs), limitaÃ§Ãµes de armazenamento e especificaÃ§Ãµes de hardware.

Para adicionar notas, vocÃª deve modificar a estrutura task_notes_LLM dentro de ai_lab_repo.py. Abaixo estÃ¡ um exemplo de conjunto de notas usadas em alguns de nossos experimentos.

```python
task_notes_LLM = [
    {"phases": ["plan formulation"],
     "note": f"You should come up with a plan for TWO experiments."},

    {"phases": ["plan formulation", "data preparation",  "running experiments"],
     "note": "Please use gpt-4o-mini for your experiments."},

    {"phases": ["running experiments"],
     "note": f"Use the following code to inference gpt-4o-mini: \nfrom openai import OpenAI\nos.environ["OPENAI_API_KEY"] = "{api_key}"\nclient = OpenAI()\ncompletion = client.chat.completions.create(\nmodel="gpt-4o-mini-2024-07-18", messages=messages)\nanswer = completion.choices[0].message.content\n"},

    {"phases": ["running experiments"],
     "note": f"You have access to only gpt-4o-mini using the OpenAI API, please use the following key {api_key} but do not use too many inferences. Do not use openai.ChatCompletion.create or any openai==0.28 commands. Instead use the provided inference code."},

    {"phases": ["running experiments"],
     "note": "I would recommend using a small dataset (approximately only 100 data points) to run experiments in order to save time. Do not use much more than this unless you have to or are running the final tests."},

    {"phases": ["data preparation", "running experiments"],
     "note": "You are running on a MacBook laptop. You can use 'mps' with PyTorch"},

    {"phases": ["data preparation", "running experiments"],
     "note": "Generate figures with very colorful and artistic design."},
    ]
```

--------
    
#### [Dica #2] ğŸš€ Usar modelos mais poderosos geralmente leva a melhores pesquisas ğŸš€

Ao conduzir pesquisas, **a escolha do modelo pode impactar significativamente a qualidade dos resultados**. Modelos mais poderosos tendem a ter maior precisÃ£o, melhores capacidades de raciocÃ­nio e melhor geraÃ§Ã£o de relatÃ³rios. Se os recursos computacionais permitirem, priorize o uso de modelos avanÃ§ados como o1-(mini/preview) ou modelos de linguagem grandes de Ãºltima geraÃ§Ã£o similares.

No entanto, **Ã© importante equilibrar desempenho e custo-benefÃ­cio**. Embora modelos poderosos possam gerar melhores resultados, eles geralmente sÃ£o mais caros e consomem mais tempo para serem executados. Considere usÃ¡-los seletivamente â€” por exemplo, para experimentos chave ou anÃ¡lises finais â€” enquanto confia em modelos menores e mais eficientes para tarefas iterativas ou prototipagem inicial.

Quando os recursos sÃ£o limitados, **otimize ajustando modelos menores** no seu conjunto de dados especÃ­fico ou combinando modelos prÃ©-treinados com prompts especÃ­ficos para a tarefa para alcanÃ§ar o equilÃ­brio desejado entre desempenho e eficiÃªncia computacional.

-----

#### [Dica #3] âœ… VocÃª pode carregar salvamentos anteriores a partir de checkpoints âœ…

**Se vocÃª perder o progresso, conexÃ£o com a internet ou se uma subtarefa falhar, vocÃª sempre pode carregar a partir de um estado anterior.** Todo o seu progresso Ã© salvo por padrÃ£o na variÃ¡vel state_saves, que armazena cada checkpoint individual. Basta passar os seguintes argumentos ao executar ai_lab_repo.py

```bash
python ai_lab_repo.py --api-key "API_KEY_AQUI" --research-topic "SUA IDEIA DE PESQUISA" --llm-backend "o1-mini" --load-existing True --load-existing-path "save_states/LOAD_PATH"
```

-----

#### [Dica #4] ğŸˆ¯ Se vocÃª estiver executando em um idioma diferente do inglÃªs ğŸˆ²

Se vocÃª estiver executando o Agent Laboratory em um idioma diferente do inglÃªs, sem problema, apenas certifique-se de fornecer uma flag de idioma para que os agentes realizem a pesquisa no seu idioma preferido. Observe que nÃ£o estudamos extensivamente a execuÃ§Ã£o do Agent Laboratory em outros idiomas, portanto, certifique-se de relatar quaisquer problemas que encontrar.

Por exemplo, se vocÃª estiver executando em chinÃªs:

```bash
python ai_lab_repo.py --api-key "API_KEY_AQUI" --research-topic "SUA IDEIA DE PESQUISA (no seu idioma)" --llm-backend "o1-mini" --language "ä¸­æ–‡"
```

----

#### [Dica #5] ğŸŒŸ HÃ¡ muito espaÃ§o para melhorias ğŸŒŸ

HÃ¡ muito espaÃ§o para melhorar esta base de cÃ³digo, entÃ£o se vocÃª acabar fazendo alteraÃ§Ãµes e quiser ajudar a comunidade, sinta-se Ã  vontade para compartilhar as mudanÃ§as que vocÃª fez! Esperamos que esta ferramenta lhe seja Ãºtil!

## ReferÃªncia / Bibtex

```bibtex
@preprint{schmidgall2025AgentLaboratory,
  title={Agent Laboratory: Using LLM Agents as Research Assistants},
  author={Schmidgall, Samuel and Su, Yusheng and Wang, Ze and Sun, Ximeng and Wu, Jialian and Yu, Xiadong and Liu, Jiang, Liu, Zicheng and Barsoum, Emad},
  year={2025}
}
```
